single batch size: 30 
batch size: 32 
epochs: 30 
split point: 0.8 
training loss: [0.03733432665467262, 0.03748403117060661, 0.04401811584830284, 0.040315959602594376, 0.02516220696270466, 0.017186768352985382, 0.014948326162993908, 0.015917910262942314, 0.014246119186282158, 0.013213623315095901, 0.012525099329650402, 0.013250434771180153, 0.014340824447572231, 0.013318991288542747, 0.013456733897328377, 0.012973127886652946, 0.012110820040106773, 0.010413543321192265, 0.010567577555775642, 0.011216714978218079, 0.011252193711698055, 0.00925731286406517, 0.008465658873319626, 0.008642940782010555, 0.00910130050033331, 0.00863583106547594, 0.0092536062002182, 0.009808797389268875, 0.010194451548159122, 0.00900394469499588] 
lowest training loss: 0.008465658873319626  
last training loss: 0.00900394469499588  
validation loss: [0.006278397049754858, 0.00229111616499722, 0.010664585046470165, 0.005361661780625582, 0.004193837288767099, 0.0008772570290602744, 0.0008542005671188235, 0.0013528745621442795, 0.000812906539067626, 0.0009254664764739573, 0.0013964767567813396, 0.0008984462474472821, 0.0011094651417806745, 0.0011588347842916846, 0.0012329441960901022, 0.0009108103695325553, 0.0015893165254965425, 0.0006927186041139066, 0.000703670084476471, 0.0010130198206752539, 0.0007034268346615136, 0.0006853496888652444, 0.0006491555832326412, 0.0006351296906359494, 0.000654607720207423, 0.000621500366833061, 0.000626634166110307, 0.0007416586158797145, 0.001110746175982058, 0.0007993635954335332] 
lowest training loss: 0.000621500366833061  
last training loss: 0.0007993635954335332  
None